{"ast":null,"code":"import _defineProperty from \"@babel/runtime/helpers/esm/defineProperty\";\n\nfunction ownKeys(object, enumerableOnly) {\n  var keys = Object.keys(object);\n\n  if (Object.getOwnPropertySymbols) {\n    var symbols = Object.getOwnPropertySymbols(object);\n    enumerableOnly && (symbols = symbols.filter(function (sym) {\n      return Object.getOwnPropertyDescriptor(object, sym).enumerable;\n    })), keys.push.apply(keys, symbols);\n  }\n\n  return keys;\n}\n\nfunction _objectSpread(target) {\n  for (var i = 1; i < arguments.length; i++) {\n    var source = null != arguments[i] ? arguments[i] : {};\n    i % 2 ? ownKeys(Object(source), !0).forEach(function (key) {\n      _defineProperty(target, key, source[key]);\n    }) : Object.getOwnPropertyDescriptors ? Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)) : ownKeys(Object(source)).forEach(function (key) {\n      Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key));\n    });\n  }\n\n  return target;\n} // copied from https://github.com/algolia/instantsearch.js/blob/688e36a67bb4c63d008d8abc02257a7b7c04e513/src/lib/voiceSearchHelper/index.ts\n// #region wrong SpeechRecognition-related types\n// This is not released in typescript yet, so we're copy&pasting the type definition from\n// https://github.com/microsoft/TypeScript-DOM-lib-generator/pull/924\n// #endregion wrong SpeechRecognition-related types\n\n\nexport default function createVoiceSearchHelper(_ref) {\n  var searchAsYouSpeak = _ref.searchAsYouSpeak,\n      language = _ref.language,\n      onQueryChange = _ref.onQueryChange,\n      onStateChange = _ref.onStateChange;\n  var SpeechRecognitionAPI = window.webkitSpeechRecognition || window.SpeechRecognition;\n\n  var getDefaultState = function getDefaultState(status) {\n    return {\n      status: status,\n      transcript: '',\n      isSpeechFinal: false,\n      errorCode: undefined\n    };\n  };\n\n  var state = getDefaultState('initial');\n  var recognition;\n\n  var isBrowserSupported = function isBrowserSupported() {\n    return Boolean(SpeechRecognitionAPI);\n  };\n\n  var isListening = function isListening() {\n    return state.status === 'askingPermission' || state.status === 'waiting' || state.status === 'recognizing';\n  };\n\n  var setState = function setState() {\n    var newState = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    state = _objectSpread(_objectSpread({}, state), newState);\n    onStateChange();\n  };\n\n  var getState = function getState() {\n    return state;\n  };\n\n  var resetState = function resetState() {\n    var status = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 'initial';\n    setState(getDefaultState(status));\n  };\n\n  var onStart = function onStart() {\n    setState({\n      status: 'waiting'\n    });\n  };\n\n  var onError = function onError(event) {\n    setState({\n      status: 'error',\n      errorCode: event.error\n    });\n  };\n\n  var onResult = function onResult(event) {\n    setState({\n      status: 'recognizing',\n      transcript: event.results[0] && event.results[0][0] && event.results[0][0].transcript || '',\n      isSpeechFinal: event.results[0] && event.results[0].isFinal\n    });\n\n    if (searchAsYouSpeak && state.transcript) {\n      onQueryChange(state.transcript);\n    }\n  };\n\n  var onEnd = function onEnd() {\n    if (!state.errorCode && state.transcript && !searchAsYouSpeak) {\n      onQueryChange(state.transcript);\n    }\n\n    if (state.status !== 'error') {\n      setState({\n        status: 'finished'\n      });\n    }\n  };\n\n  var start = function start() {\n    recognition = new SpeechRecognitionAPI();\n\n    if (!recognition) {\n      return;\n    }\n\n    resetState('askingPermission');\n    recognition.interimResults = true;\n\n    if (language) {\n      recognition.lang = language;\n    }\n\n    recognition.addEventListener('start', onStart); // @ts-ignore: refer to the top `wrong SpeechRecognition-related types` comments\n\n    recognition.addEventListener('error', onError);\n    recognition.addEventListener('result', onResult);\n    recognition.addEventListener('end', onEnd);\n    recognition.start();\n  };\n\n  var dispose = function dispose() {\n    if (!recognition) {\n      return;\n    }\n\n    recognition.stop();\n    recognition.removeEventListener('start', onStart); // @ts-ignore: refer to the top `wrong SpeechRecognition-related types` comments\n\n    recognition.removeEventListener('error', onError);\n    recognition.removeEventListener('result', onResult);\n    recognition.removeEventListener('end', onEnd);\n    recognition = undefined;\n  };\n\n  var stop = function stop() {\n    dispose(); // Because `dispose` removes event listeners, `end` listener is not called.\n    // So we're setting the `status` as `finished` here.\n    // If we don't do it, it will be still `waiting` or `recognizing`.\n\n    resetState('finished');\n  };\n\n  var toggleListening = function toggleListening() {\n    if (!isBrowserSupported()) {\n      return;\n    }\n\n    if (isListening()) {\n      stop();\n    } else {\n      start();\n    }\n  };\n\n  return {\n    getState: getState,\n    isBrowserSupported: isBrowserSupported,\n    isListening: isListening,\n    toggleListening: toggleListening,\n    dispose: dispose\n  };\n}","map":null,"metadata":{},"sourceType":"module"}